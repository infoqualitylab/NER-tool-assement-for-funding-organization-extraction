{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmwRNSTFoSO_"
   },
   "source": [
    "# Application of Named Entity Recognition tools on Funding Information\n",
    "\n",
    "A code implemented to extract named entites from a text. NER tools are used for extracting organization names from funding information obtained from PubMed research papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Jqzdtc0jngV"
   },
   "source": [
    "# 1. Setting up the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d_Cz3JC5cTkZ",
    "outputId": "fbe061d3-5bec-4339-a83c-cfaf77cb9871"
   },
   "outputs": [],
   "source": [
    "# Connecting the google colab noteboook to google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9n8X1fR7_mX"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "t_0 = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1GJ6zV2b_pD"
   },
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JLq8LpXHcjGK",
    "outputId": "dbb155f2-a2cf-409b-a290-9943743cb375"
   },
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "ack_df = pd.read_csv(\"cumulative_ack_data.csv\")\n",
    "ack_df.columns = ['Article_Title', 'PMC_ID', 'DOI', 'acknowledgement']\n",
    "ack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alpdYtYWclzU"
   },
   "outputs": [],
   "source": [
    "# removing the rows for which there is no funding information\n",
    "ack_df = ack_df[ack_df['acknowledgement'] != 'na']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUFM6FA4jukp"
   },
   "source": [
    "# 2. Applying NER on funding information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0w9ztXVkLlb"
   },
   "source": [
    "## 1. Spacy EntityRecognizer (en_core_web_sm)\n",
    "\n",
    "ner categories - LOC, MISC, ORG, PER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYny78dJdMbw",
    "outputId": "700dc72d-acc3-491c-dbb3-034832b79562"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Test sentence\n",
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "for ent in doc.ents:\n",
    "  print(ent,ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eY4GlhxhtD-"
   },
   "outputs": [],
   "source": [
    "# applying the EntityRecognizer to the acknowledgement dataset\n",
    "ack_ner = []\n",
    "for ele in ack_df['acknowledgement']:\n",
    "  ele = nlp(ele).ents\n",
    "  temp = {}\n",
    "  for ent in ele:\n",
    "    if ent.label_ in temp:\n",
    "      temp[ent.label_].append(ent.text)\n",
    "    else:\n",
    "      temp[ent.label_] = [ent.text]\n",
    "  \n",
    "  ack_ner.append(temp)\n",
    "  \n",
    "ack_df['NER_Spacy (en_core_web_sm)'] = ack_ner\n",
    "ack_df.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YltbETPovZ_A"
   },
   "outputs": [],
   "source": [
    "ack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3cCyznXhuVf"
   },
   "outputs": [],
   "source": [
    "print(ack_df.loc[4,:]['acknowledgement'])\n",
    "print(ack_df.loc[4,:]['NER_Spacy (en_core_web_sm)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Hc0GobYkVP6"
   },
   "source": [
    "## 2. Spacy EntityRecognizer (en_core_web_md)\n",
    "\n",
    "ner categories - CARDINAL, DATE, EVENT, FAC, GPE, LANGUAGE, LAW, LOC, MONEY, NORP, ORDINAL, ORG, PERCENT, PERSON, PRODUCT, QUANTITY, TIME, WORK_OF_ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jer-MIvGnXqF"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/56927602/unable-to-load-the-spacy-model-en-core-web-lg-on-google-colab\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Test sentence\n",
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "for ent in doc.ents:\n",
    "  print(ent,ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKa9IIQWngHx"
   },
   "outputs": [],
   "source": [
    "# applying the EntityRecognizer to the acknowledgement dataset\n",
    "ack_ner = []\n",
    "for ele in ack_df['acknowledgement']:\n",
    "  ele = nlp(ele).ents\n",
    "  temp = {}\n",
    "  for ent in ele:\n",
    "    if ent.label_ in temp:\n",
    "      temp[ent.label_].append(ent.text)\n",
    "    else:\n",
    "      temp[ent.label_] = [ent.text]\n",
    "  \n",
    "  ack_ner.append(temp)\n",
    "  \n",
    "ack_df['NER_Spacy (en_core_web_md)'] = ack_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxeMZ01SnkOy"
   },
   "outputs": [],
   "source": [
    "ack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6rWOUlYnnhO"
   },
   "outputs": [],
   "source": [
    "print(ack_df.loc[1,:]['acknowledgement'])\n",
    "print(ack_df.loc[1,:]['NER_Spacy (en_core_web_md)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNIGwzM-kbEo"
   },
   "source": [
    "## 3. Spacy EntityRecognizer (en_core_web_lg)\n",
    "\n",
    "ner categories  - CARDINAL, DATE, EVENT, FAC, GPE, LANGUAGE, LAW, LOC, MONEY, NORP, ORDINAL, ORG, PERCENT, PERSON, PRODUCT, QUANTITY, TIME, WORK_OF_ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_vE8m2YvJps"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/56927602/unable-to-load-the-spacy-model-en-core-web-lg-on-google-colab\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Test sentence\n",
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "for ent in doc.ents:\n",
    "  print(ent,ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QUYON9dvZvI"
   },
   "outputs": [],
   "source": [
    "# applying the EntityRecognizer to the acknowledgement dataset\n",
    "ack_ner = []\n",
    "for ele in ack_df['acknowledgement']:\n",
    "  ele = nlp(ele).ents\n",
    "  temp = {}\n",
    "  for ent in ele:\n",
    "    if ent.label_ in temp:\n",
    "      temp[ent.label_].append(ent.text)\n",
    "    else:\n",
    "      temp[ent.label_] = [ent.text]\n",
    "  \n",
    "  ack_ner.append(temp)\n",
    "  \n",
    "ack_df['NER_Spacy (en_core_web_lg)'] = ack_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lpe-2iQvdpo"
   },
   "outputs": [],
   "source": [
    "ack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVG_DuMPxzp5"
   },
   "outputs": [],
   "source": [
    "print(ack_df.loc[1,:]['acknowledgement'])\n",
    "print(ack_df.loc[1,:]['NER_Spacy (en_core_web_lg)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiav1EE1qRKw"
   },
   "source": [
    "4. Flair - English NER in Flair (large model) - 4 class model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADt_uK1Gkgzg"
   },
   "source": [
    "## 4. Flair - English NER in Flair (large model)\n",
    "\n",
    "4 class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5klrEL-rr5Ut"
   },
   "outputs": [],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jZcAjs9KEaS"
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFM04FRBKvSN"
   },
   "outputs": [],
   "source": [
    "# Make a sentence\n",
    "sentence = Sentence(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "# Load the NER tagger\n",
    "# This file is around 1.5 GB so will take a little while to load.\n",
    "tagger = SequenceTagger.load(\"flair/ner-english-large\")\n",
    "\n",
    "# Run NER over sentence\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCuZ6I8uMGQ8"
   },
   "outputs": [],
   "source": [
    "# print predicted NER spans\n",
    "print('The following NER tags are found:')\n",
    "# iterate over entities and print\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP9a1zMgMyck"
   },
   "outputs": [],
   "source": [
    "# applying the Flair to the acknowledgement dataset\n",
    "ack_ner = []\n",
    "for ele in ack_df['acknowledgement']:\n",
    "  sentence = Sentence(ele)\n",
    "  tagger.predict(sentence)\n",
    "  ner_sent = sentence.get_spans('ner')\n",
    "  temp = {}\n",
    "  for ent in ner_sent:\n",
    "    ent_label = ent.get_label(\"ner\").value\n",
    "    ent_text = ent.text\n",
    "\n",
    "    if ent_label in temp:\n",
    "      temp[ent_label].append(ent_text)\n",
    "    else:\n",
    "      temp[ent_label] = [ent_text]\n",
    "  \n",
    "  ack_ner.append(temp)\n",
    "  \n",
    "\n",
    "ack_df['NER_Flair'] = ack_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXB1sPrkO26O"
   },
   "outputs": [],
   "source": [
    "ack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1tdvv8Uz-9U"
   },
   "outputs": [],
   "source": [
    "print(ack_df.loc[1,:]['acknowledgement'])\n",
    "print(ack_df.loc[1,:]['NER_Flair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eomD8PgYktM-"
   },
   "source": [
    "# Output Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mj53M1MVsUh2"
   },
   "outputs": [],
   "source": [
    "# extracting the organization entity from NER_Spacy (en_core_web_sm)\n",
    "ner_org = []\n",
    "for ele in ack_df['NER_Spacy (en_core_web_sm)']:\n",
    "  temp = []\n",
    "  if len(ele) != 0 and 'ORG' in ele.keys():\n",
    "    temp = ele['ORG']\n",
    "    ner_org.append(temp)\n",
    "  else:\n",
    "    ner_org.append(\"NA\")\n",
    "\n",
    "ack_df['NER_spacy_sm_org'] = ner_org\n",
    "\n",
    "# extracting the organization entity from NER_Spacy (en_core_web_md)\n",
    "ner_org = []\n",
    "for ele in ack_df['NER_Spacy (en_core_web_md)']:\n",
    "  temp = []\n",
    "  if len(ele) != 0 and 'ORG' in ele.keys():\n",
    "    temp = ele['ORG']\n",
    "    ner_org.append(temp)\n",
    "  else:\n",
    "    ner_org.append(\"NA\")\n",
    "\n",
    "ack_df['NER_spacy_md_org'] = ner_org\n",
    "    \n",
    "# extracting the organization entity from NER_Spacy (en_core_web_lg)\n",
    "ner_org = []\n",
    "for ele in ack_df['NER_Spacy (en_core_web_lg)']:\n",
    "  temp = []\n",
    "  if len(ele) != 0 and 'ORG' in ele.keys():\n",
    "    temp = ele['ORG']\n",
    "    ner_org.append(temp)\n",
    "  else:\n",
    "    ner_org.append(\"NA\")\n",
    "\n",
    "ack_df['NER_spacy_lg_org'] = ner_org\n",
    "\n",
    "\n",
    "# extracting the organization entity from NER_Flair\n",
    "ner_org = []\n",
    "for ele in ack_df['NER_Flair']:\n",
    "  temp = []\n",
    "  if len(ele) != 0 and 'ORG' in ele.keys():\n",
    "    temp = ele['ORG']\n",
    "    ner_org.append(temp)\n",
    "  else:\n",
    "    ner_org.append(\"NA\")\n",
    "\n",
    "ack_df['NER_Flair_org'] = ner_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nquDLyam3o4n"
   },
   "outputs": [],
   "source": [
    "ack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKC_zfmd5Kj-"
   },
   "outputs": [],
   "source": [
    "# saving the file to csv\n",
    "ack_df.to_csv(\"/content/ack_ner.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISdnhZf3h-8e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JInyyCuv4F02"
   },
   "outputs": [],
   "source": [
    "with open('drive/MyDrive/ack_ner.pickle', 'wb') as handle:\n",
    "    pickle.dump(ack_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQ6DTtzX84pI"
   },
   "outputs": [],
   "source": [
    "t_1 = timeit.default_timer()\n",
    "print(\"The time elapsed: \", t_1 - t_0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
